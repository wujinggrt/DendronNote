---
id: q7dxzctr9o2vqh1m6v0milj
title: Large_Behavior_Models
desc: ''
updated: 1752913122384
created: 1752908942458
---

好的，这就为您整理这篇名为《A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation》的论文摘要。

## 论文总结

### 作者、团队信息、论文标题、论文链接、项目主页

*   **作者:** TRI LBM Team (丰田研究院大型行为模型团队)
*   **团队信息:** Toyota Research Institute (TRI)
*   **论文标题:** A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation (对用于多任务灵巧操作的大型行为模型进行的仔细研究)
*   **论文链接:** `arXiv:submit/6601186 [cs.RO] 7 Jul 2025`
*   **项目主页:** https://toyotaresearchinstitute.github.io/lbm/

### 主要贡献

1.  **严谨的评估流程:** 提出并验证了一套严谨的评估流程，用于在模拟和真实世界环境中，通过盲测、随机试验和统计置信度分析，严格评估多任务机器人操作策略（大型行为模型 LBMs）的能力。
2.  **多任务预训练的价值:** 实验证明，与从零开始训练的单任务基线模型相比，经过多任务预训练的 LBMs 在学习新任务时更高效、性能更优越，并且在面对与训练环境不同的新情况时（分布外泛化）表现出更强的鲁棒性。
3.  **数据效率的提升:** 研究发现，经过预训练的 LBMs 仅需少量任务相关的演示数据进行微调，即可达到甚至超越使用全部数据从头训练的单任务模型的性能水平。具体来说，在仿真环境中，微调 LBM 所需数据量不到从头训练的 30%。
4.  **规模效应的验证:** 研究结果显示，随着预训练数据规模和多样性的增加，微调后模型的性能也随之平稳提升，并未发现性能拐点。

### 研究背景

#### 研究问题

尽管近年来机器人模仿学习取得了巨大进步，但如何构建一个能灵活、通用地执行多种复杂操作任务的机器人系统，仍然是机器人研究的核心目标。当前基于行为克隆的方法在特定任务上表现出色，但泛化能力有限，难以适应任务或环境的变化。

#### 研究难点

*   **评估挑战:** 缺乏标准化的硬件和评估框架，使得对通用机器人模型的性能进行有意义且可复现的评估变得困难。
*   **数据获取:** 收集大规模、多样化且高质量的真实世界机器人操作数据成本高昂且耗时。
*   **模拟与现实的差距 (Sim-to-Real Gap):** 仿真环境与真实世界在动力学和视觉上的差异，给策略的实际部署带来了挑战。
*   **模型泛化性:** 如何让模型从有限的演示数据中学习到可泛化至新物体、新场景和新任务的技能，是一个核心难题。

#### 相关工作

| **领域研究**           | **已有方法**                                                                                                   | **局限性**                                                                     | **本文改进**                                                                                                          |
| :--------------------- | :------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------- |
| **大规模机器人学习**   | 使用大规模、多样化的数据集训练高容量模型（如 Transformer 架构的 VLA 模型），并利用大型预训练模型进行知识迁移。 | 数据异构性、灾难性遗忘、多模态融合、实时推理速度等问题仍是开放性研究挑战。     | 专注于严格评估多任务预训练本身的效果，采用固定的策略架构，以隔离变量。                                                |
| **机器人学习数据集**   | 通过人类远程遥操作、专用设备或仿真环境收集数据，并汇集多个来源的数据（如 Open X-Embodiment）。                 | 真实世界数据收集缓慢昂贵；仿真与现实存在差异；数据质量参差不齐。               | 混合使用内部收集的高质量真实和仿真数据以及公开数据集进行预训练，并利用仿真进行高效评估。                              |
| **机器人操作策略评估** | 主要依赖基于仿真的基准测试（如 RLBench, ManiSkill），使用成功率、任务完成度等指标。                            | 真实世界评估缺乏标准化，难以衡量复杂长时程任务，且无法充分评估鲁棒性和安全性。 | 设计了包含盲测 A/B test、严格控制初始条件、大规模试验和稳健统计分析的严谨评估流程，并在真实世界中进行了 1800 次试验。 |

### 方法

本文将 **Diffusion Policy** 范式扩展，提出了一种名为 **大型行为模型 (Large Behavior Models, LBMs)** 的多任务机器人操作策略。

1.  **模型架构 (LBM Architecture):**
    *   核心是一个 **Diffusion Transformer (DiT)**，它以视觉、语言和本体感知信息为条件，生成机器人动作。
    *   **输入:** 包括多视角的 RGB 图像、自然语言指令以及机器人末端执行器的位姿。
    *   **特征提取:** 图像特征由预训练的 CLIP ViT 提取；语言特征由 CLIP 文本编码器提取。
    *   **动作生成:** 采用 **Denoising Diffusion Implicit Models (DDIM)** 生成动作序列。模型通过一个去噪过程，将高斯噪声逐步转化为结构化的、连续的 20 维双臂动作序列（预测未来 16 个时间步）。
    *   **训练:** 模型优化的目标函数是预测在加噪过程中添加的噪声，其损失函数为：$$ L(\theta) = E_{t, A^0, \epsilon_k} \left[ ||\epsilon_k - \epsilon_\theta(O_t, A^k, k)||^2 \right] $$ 其中 $ \epsilon_\theta $ 是带参数 $ \theta $ 的噪声预测网络， $ A^k $ 是加噪后的动作， $ O_t $ 是观测值。

2.  **数据策略:**
    *   **预训练:** 在一个名为 **Ramen** 的混合数据集上进行预训练。该数据集包含约 1695 小时的机器人演示数据，由丰田研究院内部收集的真实与仿真数据 **TRI-Ramen** (约 545 小时) 和外部精选的 **OXE-Ramen** 数据集 (约 1150 小时) 组成。
    *   **微调 (Finetuning):** 将预训练好的 LBM 在特定的下游任务数据上进行微调，以使其成为该任务的“专家”模型。

3.  **评估协议 (Evaluation Protocol):**
    *   **公平比较:** 采用盲测方式，评估者在不知晓当前测试策略的情况下进行评估，并通过随机化策略顺序来减少偏差。
    *   **可复现性:** 在真实世界评估中，通过图像叠加的方式确保不同策略面对的初始场景条件高度一致。在仿真中，使用相同的随机种子。
    *   **量化指标:** 除了二元的成功/失败率 (Success Rate, SR) 外，还引入了基于里程碑的 **任务完成度 (Task Completion, TC)** 指标，以更细致地量化策略的表现。
    *   **统计分析:** 使用贝叶斯分析来量化结果的不确定性，并采用紧凑字母表示法 (Compact Letter Display, CLD) 来展示多策略比较中的统计显著性差异。
    *   **分布偏移 (Distribution Shift):** 设计了多种评估条件，包括 **标称条件 (Nominal)** 和 **分布偏移条件**，后者通过改变物体、光照、机器人站位等来测试模型的鲁棒性。

### 实验与结论

#### 实验设置

*   **平台:** 实验在包含两台 Franka FR3 机械臂的双臂桌面操作平台上进行，涵盖了模拟和真实世界两种环境。
*   **任务:** 评估任务分为两类：
    *   **“见过”的任务 (Seen Tasks):** 在预训练数据中出现过的任务。
    *   **“未见过”的任务 (Unseen Tasks):** 未在预训练数据中出现的全新任务，包括需要高灵巧度的长时程、多步骤复杂任务（如安装自行车碟刹、清理猫砂、准备早餐）。
*   **对比方法:**
    *   **单任务基线 (Single-Task):** 针对每个任务，使用其全部演示数据从头训练的模型。
    *   **预训练 LBM (Pretrained LBM):** 仅经过大规模数据预训练，未针对特定任务微调的模型。
    *   **微调 LBM (Finetuned LBM):** 在预训练基础上，使用特定任务数据进行微调的模型。

#### 结论

1.  **微调 LBM 优于单任务基线:** 无论是在“见过”还是“未见过”的任务上，在标称和分布偏移条件下，微调后的 LBM 在聚合性能上均显著优于单任务基线模型。尤其是在任务完成度上，优势更为明显。
2.  **微调 LBM 更具鲁棒性:** 当引入分布偏移时（例如更换物体、改变环境），所有模型的性能都会下降。但微调 LBM 的性能下降幅度小于单任务基线，显示出更强的鲁棒性。
3.  **LBM 仅需少量数据即可达到高水平:** 实验表明，在“未见过”的任务上，微调 LBM 仅需 15% 的任务数据，其性能便可超越使用 100% 数据训练的单任务基线。仿真实验的聚合结果显示，达到相似性能，微调 LBM 所需数据不到从头训练的 30%。
4.  **预训练数据规模越大，性能越好:** 通过在不同规模的预训练数据集上训练 LBM，研究发现，预训练数据越多、越多样化，微调后的模型性能就越好，这一趋势是平滑的。

### 不足

1.  **训练过程的随机性未被充分考虑:** 本研究的分析没有显式地考虑模型训练过程中的随机性对最终策略性能的影响。由于成本限制，每个策略架构只训练了一次。
2.  **真实世界评估的噪声:** 尽管采用了严格的实验流程，但真实世界的评估（如初始条件设置、人工评分）仍不可避免地存在误差和噪声，这可能导致一些微小的性能差异无法被检测出来。
3.  **语言模型的规模有限:** 本研究中使用的 LBM 语言编码器规模适中（基于 CLIP），虽然研究结果预计能推广到更大的视觉-语言-动作 (VLA) 模型，但像语言引导的灵活性等方面的表现可能会因模型规模而异。
4.  **数据处理方式的影响:** 论文发现，像数据归一化和数据过滤这类设计决策对下游性能有很大影响，有时甚至超过了算法或架构本身的改变。这提示在比较不同方法时需要格外谨慎。

## 数据集准备

好的，根据论文内容，该研究中的数据集准备工作非常细致和系统化，是其研究方法的核心组成部分之一。

总的来说，他们构建了一个名为 **Ramen** 的大规模、异构机器人操作数据集，总时长约 **1695 小时**，用于模型的预训练。这个数据集由两大部分组成：

1.  **TRI-Ramen** (内部数据集, 约 545 小时)
2.  **OXE-Ramen** (外部数据集, 约 1150 小时)

以下是详细的准备过程：

### 1. 数据集构成 (Ramen)

#### a. TRI-Ramen (内部高质量数据集)
这部分数据由丰田研究院 (TRI) 内部收集，以保证数据质量和多样性，它又分为三个子集：
*   **TRI-Ramen-Real (468 小时):**
    *   **来源:** 在 9 个真实世界的双臂机器人平台上，由人类操作员通过远程遥操作 (teleoperation) 收集。
    *   **内容:** 涵盖 362 个不同的任务和 46063 个演示。
*   **TRI-Ramen-Sim (45 小时):**
    *   **来源:** 在 2 个仿真机器人平台上收集。
    *   **内容:** 包含 41 个任务和 7348 个演示，用于补充真实世界数据。
*   **TRI-Ramen-UMI (32 小时):**
    *   **来源:** 使用一种名为“通用操作接口 (Universal Manipulation Interface)”的手持设备收集，这种方式不依赖于真实的机器人，可以在“野外 (in-the-wild)”环境中快速收集数据。
    *   **内容:** 包含 129 个任务和 10851 个演示。

#### b. OXE-Ramen (外部精选数据集)
*   **来源:** 这是从公开的大规模机器人数据集 **OpenX-Embodiment** 中精选出来的一个子集。
*   **筛选标准:** 根据物体和环境的多样性、总片段数量等启发式规则进行筛选，以扩充预训练数据的广度。

### 2. 数据处理与统一化 (关键步骤)
为了将来自不同来源、不同机器人、不同格式的数据融合在一起进行训练，研究团队进行了一系列关键的数据处理和统一化工作：

1.  **统一观测和动作空间:**
    *   **观测空间 (Observation Space):** 包含了 i) 相对于工作台中心的末端执行器位姿，ii) 两个末端执行器之间的相对位姿，iii) 连续的夹爪宽度，iv) 6 个 RGB 摄像头图像 (缺失的用零填充)，v) 一条自然语言指令。
    *   **动作空间 (Action Space):** 包含了相对于机器人基座的末端执行器位姿和夹爪宽度。其中，姿态方向用一个 6D 向量表示（旋转矩阵的前两行）。
    *   **数据格式转换:** 来自外部数据集 (OXE-Ramen) 的数据被映射和转换，以符合 TRI-Ramen 的数据格式。例如，将单臂数据通过零填充和随机交换手臂的方式转换为双臂数据。

2.  **语言指令处理:**
    *   每个数据片段都包含一个由人类编写的指令。
    *   为了增强泛化性，他们还使用大语言模型 (ChatGPT) 为每条人工指令生成了 5 个替代版本的指令。
    *   对于外部数据集中缺失语言标注的部分，会填充一个通用的文本，如“do something useful”。

3.  **数据归一化 (Data Normalization):**
    *   这是一个非常重要的步骤。他们对每个特征维度 (如末端执行器的位置) 和每个时间步进行独立的归一化。
    *   他们没有使用简单的最大-最小值归一化，而是使用第 2 和第 98 百分位数 ($$ x^{0.02} $$ 和 $$ x^{0.98} $$) 来缩放数据，将 96% 的核心数据线性地映射到 `[-1, 1]` 区间，然后将整个数据裁剪到 `[-1.5, 1.5]` 区间。
    *   **公式为:** $$ y_i = \min(\max(-1.5, 2 \times \frac{x_i - x^{0.02}}{x^{0.98} - x^{0.02}} - 1), 1.5) $$
    *   这种方法的好处是保留了数据分布的中心区域的分辨率，同时又保留了一些离群值，避免了极端值对整体数据分布的影响。
    *   **值得注意的是，** 论文提到他们在代码中发现了一个归一化错误，即在预训练期间，一些数据批次被错误地归一化了。他们后续的分析表明，这个错误对标称条件下的性能影响不大，但在分布偏移下，正确归一化的模型表现更好。

4.  **数据集过滤 (Dataset Filtering):**
    *   **问题:** 团队发现，很多演示的开头部分存在长时间的低运动或无运动帧（可能是操作员准备或 UI 加载延迟导致）。
    *   **解决方案:** 他们设定了一个运动阈值（夹爪平移超过 5 厘米或旋转超过 15 度），并移除了每个演示中达到该阈值之前的所有数据帧。
    *   **意外发现:** 这个过滤操作带来了一个有趣的权衡。对于单任务模型，过滤后性能提升了。但对于预训练的 LBM，过滤后虽然启动更快，但出现了更严重的“语言可操纵性”问题（即更容易执行错误的指令），导致性能意外下降。因此，最终他们决定在 **预训练时使用未经过滤的数据**，而在 **微调和训练单任务基线时使用过滤后的数据**。

5.  **批次平衡 (Batch Balancing):**
    *   在训练期间，为了确保每个数据来源都能被有效学习，他们根据经验设定了一组权重，来平衡每个批次中来自不同数据集（如 lbm_real, lbm_sim, droid 等）的样本数量。

### 3. 评估数据集的准备

*   **“见过”的任务:** 从预训练数据集 TRI-Ramen-Sim 中随机选择了 16 个任务用于仿真评估，并选择了其中 3 个任务（有匹配的真实世界数据）用于真实世界评估。
*   **“未见过”的任务:** 设计了 8 个全新的仿真任务（包括一个全新的 "Kitchen" 场景）和 5 个全新的真实世界任务（这些任务更复杂、更长时程）。

通过以上详尽的准备流程，研究团队构建了一个庞大、多样且经过精心处理的数据基础，为后续严格评估大型行为模型 (LBMs) 的性能和泛化能力奠定了坚实的基础。