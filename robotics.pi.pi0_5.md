---
id: jbtl05o5webpw7klu49b9go
title: Pi0_5
desc: ''
updated: 1750667272191
created: 1750666685394
---

## 论文总结

### 作者、团队信息、论文标题、论文链接、项目主页

*   **作者：** Kevin Black, Noah Brown...
*   **团队信息：** Physical Intelligence (根据署名下的描述)
*   **论文标题：** π0.5: a Vision-Language-Action Model with Open-World Generalization (π0.5: 一个具有开放世界泛化能力的视觉-语言-动作模型)
*   **论文链接：** 论文本身未直接提供 arXiv 链接，但提到了项目主页。一般这类论文会发布在 arXiv 上。(OCR 内容基于论文打印版，实际链接需查找)
*   **项目主页：** [https://pi.website/blog/pi05](https://pi.website/blog/pi05)

### 主要贡献

1.  **提出 π0.5 模型：** 一个基于 π0 的新型视觉-语言-动作 (VLA) 模型，通过在异构任务上进行联合训练 (co-training)，实现了广泛的泛化能力。
2.  **异构数据联合训练：** π0.5 利用来自多种来源的数据，包括多个机器人平台、高层语义预测、网络数据以及其他来源，以实现广泛的真实世界机器人操作泛化。
3.  **混合多模态样本：** 系统采用联合训练和混合多模态样本的组合，这些样本结合了图像观察、语言指令、对象检测、语义子任务预测和低层动作。
4.  **首次实现复杂任务泛化：** 首次展示了一个端到端学习赋能的机器人系统，能够在全新的家庭环境中执行长时间 (10-15 分钟)、灵巧的操作技能，如清洁厨房或卧室。
5.  **验证知识迁移的重要性：** 实验证明，这种知识迁移对于有效的泛化至关重要。
6.  **分层推理架构：** 模型采用简单的分层架构，在推理时首先预测高层语义子任务，然后基于该子任务预测低层机器人动作。

### 研究背景（研究问题，研究难点和相关工作）

*   **研究问题：**
    为了使机器人真正有用，它们必须能够在实验室之外的真实世界中执行实际相关的任务。一个核心问题是如何让基于学习的机器人控制系统在“野外”环境中实现广泛的泛化能力，特别是在面对全新的环境和物体时，执行复杂的、长时程的任务。

*   **研究难点：**
    1.  **数据多样性与规模：** 真实世界的多样性要求训练数据具有极大的广度。简单地扩大特定任务的数据量不足以实现泛化，需要覆盖多种抽象层次的知识。
    2.  **异构数据融合：** 如何有效地从多种来源 (不同机器人、网络数据、语言指令等) 整合知识，这些数据来源的格式、质量和相关性各不相同。
    3.  **长时程任务推理：** 许多实际任务 (如打扫房间) 涉及多个步骤和长时间的执行，需要机器人具备高层规划和推理能力，而不仅仅是反应式动作。
    4.  **对新环境的零样本/少样本泛化：** 理想情况下，机器人应能在从未见过的环境中直接部署并有效工作，这对模型的泛化能力提出了极高要求。
    5.  **复杂技能学习：** 诸如整理床铺、擦拭污渍等灵巧操作技能难以通过简单模仿学习掌握，尤其是在新情境下。

*   **相关工作：**

    | 领域研究                                                                                       | 已有方法                                                                                                                          | 局限性                                                                                             | 本文改进 (π0.5)                                                                                                                      |
    | :--------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------- |
    | 通用机器人操作策略 (Generalist robot manipulation policies)                                    | 扩大训练数据集覆盖多种场景和任务；使用 VLA 模型 (如 RT-1, Palm-E) 利用预训练 VLM 的语义知识。                                     | 通常在与训练数据相似的环境中评估；对于复杂、长时程任务，通过暴力收集机器人数据实现广泛覆盖不可行。 | 在完全未见过的新场景 (新厨房、卧室) 中评估，通过整合多源数据 (非自身平台经验) 实现泛化，而不仅仅依赖目标平台的直接经验。             |
    | 非机器人数据联合训练 (Non-robot data co-training)                                              | 使用计算机视觉数据集初始化视觉编码器；利用现成的任务规划器；VLA 通常从预训练 VLM 初始化；将 VLA 与 VLM 训练数据混合进行联合训练。 | 现有联合训练主要集中于 VLM 数据，以提升对新物体或背景的泛化。                                      | 进一步扩展了联合训练的数据源，包括来自其他机器人的数据、高层语义子任务预测、人类监督员的口头指令等更广泛的、与机器人相关的监督信号。 |
    | 基于语言的机器人推理与规划 (Robot reasoning and planning with language)                        | 使用高层推理 (如 LLM/VLM 预测子任务) 增强端到端策略在长时程任务上的性能；通常采用两阶段推理：VLM 预测语义步骤，独立低层策略执行。 | 许多方法使用两个独立的模型进行高层规划和低层控制。                                                 | 使用统一模型进行高层 (预测语义子任务) 和低层 (预测动作) 推理，更接近 CoT 或测试时计算的思路。高层推理频率低于低层动作推理。          |
    | 具有开放世界泛化能力的机器人学习系统 (Robotic learning systems with open-world generalization) | 针对基本操作 (如抓取) 或任务特定假设 (如抓取预测) 的方法能在新家庭中泛化；大规模多领域数据集促进简单端到端任务向新环境泛化。      | 现有演示的任务相对简单，时长短，成功率不高。                                                       | 能够在新卧室中执行长时程、多阶段任务 (如整理所有衣物、铺床)，并在完全未见过的环境中泛化。                                            |

### 方法

π0.5 模型的设计和训练流程如下图 Fig. 3 所示，主要包括模型架构、混合动作表示以及两阶段训练。

1.  **π0.5 模型架构 (The π0.5 architecture):**
    *   模型基于 Transformer 架构，能够灵活处理动作序列和 token 化文本输出。
    *   输入包括多摄像头图像 ($I_1, ..., I_r$)、机器人本体状态 ($q_t$)、整体任务提示 ($l$)。
    *   输出包括预测的高层子任务 ($\hat{l}$) 或对视觉语言问题的回答 (文本)，以及预测的动作块 ($a_{t:t+H}$)。
    *   分布分解为：$$ \pi_\theta(a_{t:t+H}, \hat{l} | o_t, l) = \pi_\theta(a_{t:t+H} | o_t, \hat{l}) \pi_\theta(\hat{l} | o_t, l) $$
    *   高层推理 ($\pi_\theta(\hat{l} | o_t, l)$) 和低层推理 ($\pi_\theta(a_{t:t+H} | o_t, \hat{l})$) 由同一模型表示。
    *   图像块、文本提示和连续动作 token 使用双向注意力，而文本输出 token (如子任务) 使用因果注意力。
    *   模型输出分为文本 token logits (用于采样 $\hat{l}$) 和由独立动作专家 (action expert) 生成的动作输出 token (用于得到 $a_{t:t+H}$)。

2.  **混合离散与连续动作表示 (Combining discrete & continuous action representations):**
    *   借鉴 π0，使用流匹配 (flow-matching) 预测连续动作。给定 $a_{t:t+H}$，噪声版本 $\tilde{a}^\tau_{t:t+H} = \tau a_{t:t+H} + (1-\tau)\omega, \omega \sim N(0,I)$，模型预测流场 $w-a_{t:t+H}$。
    *   为了结合离散 token 训练的快速性 (如 FAST [64]) 和流匹配生成连续动作的实时推理优势，模型被训练来同时通过自回归采样 token (使用 FAST tokenizer) 和迭代积分流场来预测动作。
    *   损失函数结合了文本预测损失 (交叉熵，包括 FAST 编码的动作 token) 和流匹配损失：
        $$ L = E_{D,\tau,w} [H(x_{1:M}, \hat{y}_{1:M}(o_t, l)) + \alpha ||w - a_{t:t+H} - f^\theta_a(\tilde{a}^\tau_{t:t+H}, o_t, \hat{l})||^2_2] $$
        其中 $H$ 是交叉熵损失，$f^\theta_a$ 是动作专家的输出，$\alpha$ 是权衡参数。
    *   预训练阶段 $\alpha=0$ (仅离散动作 token)，后训练阶段 $\alpha > 0$。推理时，先自回归解码文本 token $\hat{l}$，然后基于 $\hat{l}$ 进行多步去噪生成 $a_{t:t+H}$。

3.  **预训练 (Pre-training):** (Fig. 4)
    *   模型权重从一个标准的 VLM (在网络数据上训练的 PaliGemma) 初始化。
    *   目标是使模型适应多样化的机器人任务，所有任务 (包括机器人动作) 都用离散 token 表示。
    *   训练数据源包括：
        *   **多样化移动机械臂数据 (MM):** 约 400 小时，来自约 100 个不同家庭环境的家务任务数据。
        *   **多样化多环境非移动机器人数据 (ME):** 单臂或双臂固定在不同家庭环境中的表面或平台上收集的数据。
        *   **跨模态实验室数据 (CE):** 在实验室环境下，使用多种机器人类型完成的任务数据 (如整理桌面、折叠衬衫)，包括开源 OXE 数据集。
        *   **高层子任务预测 (HL):** 对 MM, ME, CE 数据中的多子任务数据进行手动标注，提供子任务的语义描述。训练 π0.5 联合预测子任务标签 (文本) 和相应的动作。同时标注并预测当前观察中的相关边界框。
        *   **多模态网络数据 (WD):** 图像描述 (CapsFusion, COCO)、问答 (Cambrian-7M, PixMo, VQAv2)、对象定位。

4.  **后训练 (Post-training):** (Fig. 4)
    *   在预训练 (280k 梯度步) 之后，进行第二阶段训练，目标是：
        *   将模型专门用于家庭移动操作。
        *   添加动作专家 (action expert) 以通过流匹配产生连续动作块。
    *   联合训练下一 token 预测 (保留文本预测能力) 和动作专家的流匹配 (随机初始化权重)。
    *   优化目标是公式 (1) 中的组合损失，$\alpha=10.0$，进行 80k 额外梯度步。
    *   动作数据集包括 MM 和 ME 机器人数据 (筛选成功的、低于长度阈值的片段)。
    *   包含 WD 数据以保持语义和视觉能力，以及对应于多环境数据集的 HL 数据。
    *   **口头指令演示 (VI):** 额外收集口头指令数据，由专家用户提供“语言演示”，逐步选择合适的子任务指令来引导机器人完成移动操作任务。这为训练的策略提供了良好的高层子任务输出示例。

5.  **机器人系统 (Robot system details):** (Fig. 5)
    *   使用两种类型的移动机械臂，均配备两个 6DoF 臂 (平行爪手)、腕部单目 RGB 相机、轮式全向底座和躯干升降机构。
    *   手臂间有前向和后向相机。共 4 个相机用于高层推理，腕部和前向相机用于低层推理。
    *   状态和动作空间维度为 18 或 19 DoF。
    *   控制系统简单：π0.5 模型直接指令手臂、夹爪、躯干的目标姿态和底座的目标速度 (50Hz，带动作分块)。使用简单 PD 控制器跟踪目标。

### 实验与结论

*   **实验设置：** 所有实验均在训练中未见过的新型环境中进行。定量比较使用模拟家庭环境，最真实的最终评估在三个真实家庭中进行。
*   **核心问题与发现：**
    1.  **π0.5 能否有效泛化到全新家庭中的复杂多阶段任务？** (Fig. 7)
        *   **结论：是。** π0.5 在三个未曾见过的真实家庭中，成功地完成了清洁厨房 (将物品放入抽屉、将餐具放入水槽) 和整理卧室 (将衣物放入洗衣篮) 等多种任务。许多任务涉及多个阶段，持续约 2-5 分钟。模型接收简单的高层指令，高层推理过程自主决定合适的步骤。
    2.  **π0.5 的泛化能力如何随训练数据中不同环境数量扩展？** (Fig. 8, 9)
        *   **结论：环境数量越多，泛化性能越好。** 随着训练地点数量从 3 个增加到 104 个，任务平均性能和语言遵循能力 (包括对未见过类别物体的泛化) 均得到提升。完整的联合训练方案对于实现良好泛化至关重要，优于仅使用测试环境数据或仅使用 104 个地点的移动操作数据进行训练的基线。
    3.  **π0.5 训练混合物中各个联合训练成分的贡献如何？** (Fig. 10, 11)
        *   **结论：跨模态数据 (ME, CE) 非常重要。** 排除 ME 或 CE 数据会导致性能显著下降。Web 数据 (WD) 对于处理未分布 (OOD) 物体的语言遵循任务特别重要。
    4.  **π0.5 与 π0 VLA 的比较如何？** (Fig. 12)
        *   **结论：π0.5 显著优于原始 π0 和改进的 π0-FAST+Flow。** 这表明混合训练流程 (预训练离散 token，后训练流匹配动作专家) 以及 HL 和 WD 数据的加入带来了显著的性能提升。
    5.  **π0.5 的高层推理组件有多重要？它与扁平化低层推理以及 Oracle 高层基线的比较如何？** (Fig. 13)
        *   **结论：高层推理很重要，但联合训练方案本身贡献巨大。** 完整的 π0.5 (显式高层推理) 效果最好。令人惊讶的是，“隐式 HL”(训练中包含 HL 数据，但运行时无显式高层推理) 性能第二好，表明仅通过在训练混合中包含子任务预测数据就能获得大部分收益。排除 HL 数据 (no HL) 或口头指令数据 (no VI) 会导致性能显著下降。Web 数据 (no WD) 对高层策略的改进也很有帮助。零样本 GPT-4 效果最差。

*   **总体结论：**
    π0.5 是一个通过联合训练构建的模型，它整合了多种数据源，使其能够泛化到新的环境。该模型能够在从未见过的家庭中控制移动机械臂执行清洁厨房和卧室、整理床铺、挂毛巾等其他多阶段灵巧行为。π0.5 在约 400 小时的移动操作数据上训练，但包含了大量来自其他机器人 (包括不同环境中的非移动机械臂和实验室数据) 以及网络数据和高层预测数据。其泛化能力证明了这种联合训练方案促进了有效迁移，使得仅用中等规模的移动操作数据集就能实现对移动机械臂的高度泛化控制。

### 不足

1.  **仍然会犯错：** 虽然泛化能力广泛，但 π0.5 并非完美，仍会出错。
2.  **特定环境挑战：** 某些环境存在持续性挑战，例如不熟悉的抽屉把手，或机器人难以物理打开的柜子。
3.  **部分可观察性问题：** 例如，机器人手臂可能遮挡住需要擦拭的污渍。
4.  **高层子任务推理易分心：** 例如，在放置物品时可能会多次开关抽屉。
5.  **处理简单指令：** 当前模型处理的指令相对简单。更复杂的用户偏好和指令需要更精细和多样的标注来支持。
6.  **上下文窗口有限：** 模型使用的上下文相对有限，在需要跨房间导航或记忆物体位置等具有更强部分可观察性的场景中，更丰富的上下文和记忆机制可能会显著提升能力。
7.  **数据源探索：** 虽然探索了多种异构数据源的组合，但具体的数据源种类和组合方式仍有更广泛的探索空间。例如，从口头指令学习的能力提供了一种强大的新监督模式，未来可以探索更多人机交互方式以提供上下文知识。

## Ref and Tag