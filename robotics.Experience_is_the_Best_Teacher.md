---
id: y95o2fa13c069hhblzgoyjj
title: Experience_is_the_Best_Teacher
desc: ''
updated: 1754153807230
created: 1754066740009
---

Generated markdown
## 论文总结

### 作者、团队信息、论文标题、论文链接、项目主页

*   **作者**: Guowei Lan, Kaixian Qu, René Zurbrügg, Changan Chen, Christopher E. Mower, Haitham Bou-Ammar, Marco Hutter.
*   **团队信息**:
    *   ¹ Robotic Systems Lab, ETH Zurich
    *   ² ETH AI Center
    *   ³ Huawei Noah's Ark Lab
    *   ⁴ UCL Centre for AI
*   **论文标题**: Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory (经验是最好的老师：通过自生成记忆来为机器人学服务)
*   **论文链接**: [https://arxiv.org/abs/2507.16713v1](https://arxiv.org/abs/2507.16713v1)
*   **项目主页**: 经检索，该论文暂未提供公开的项目主页。

### 主要贡献

这篇论文提出了一个名为 EXPTEACH 的新框架，旨在通过构建一个由机器人真实世界经验自生成的记忆，来将视觉语言模型 (VLM) 应用于物理机器人，以解决 VLM 在多样化现实世界机器人中落地困难的挑战。主要贡献如下：

*   **自生成记忆框架**: 提出了一个结合短期记忆 (STM) 和长期记忆 (LTM) 的自生成记忆框架，用于在机器人规划中落地 VLM。
*   **记忆检索策略**: 使用检索增强生成 (RAG) 的记忆检索策略来从 LTM 中访问与任务相关的过往经验，使机器人能够在未来的相似任务和场景中正确行动。
*   **按需图像标注模块**: 引入了一个按需图像标注模块，增强了 VLM 在多种技能上的空间推理能力，从而实现了更准确、更鲁棒的动作执行。
*   **真实的物理世界验证**: 通过广泛的真实世界实验证明，EXPTEACH 能够显著提高任务成功率，并且能有效泛化至未见过的任务。具体来说，通过短期记忆中的反思，在 4 个具有挑战性的机器人任务中，成功率从 36% 提升至 84%。而在 12 个真实世界场景中，通过长期记忆，单次试验成功率从 22% 提升至 80%。

### 研究背景

#### 研究问题

视觉语言模型 (VLM) 虽然在自主规划方面表现出色，但它们通常在互联网数据上进行预训练，缺乏对特定机器人本体能力和物理环境限制的认知。这导致 VLM 在与真实世界的交互中常常会失败。例如，当一个物体被部分遮挡时，VLM 可能仍然会自信地指令机器人直接抓取，而机器人由于感知不完美很可能失败。核心问题是：如何让 VLM 意识到它所辅助的特定机器人的能力，以及如何有效地将 VLM “落地”到机器人学中？

#### 研究难点

*   **VLM 与物理世界解耦**: VLM 缺乏机器人本体的物理先验知识，无法准确理解自身的能力边界和物理交互的真实后果。
*   **经验的利用**: 如何让机器人从过去的成功和失败经验中学习，并有效地将这些经验应用于新的、相似的任务场景中，以提高决策的准确性和效率。
*   **空间理解与精确操作**: 机器人任务通常需要精确的空间感知和操作，例如抓取物体的特定部位，而 VLM 在这方面的能力有限。

#### 相关工作

| 领域研究                   | 已有方法                                                                                           | 局限性                                                                                                                           | 本文改进                                                                                                                   |
| :------------------------- | :------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- |
| **机器人中的 VLM**         | 利用 VLM 进行任务规划、动作序列生成、结果评估和失败恢复。例如 SayCan, Inner Monologue, ReplanVLM。 | 通常依赖于外部监督信号，缺乏来自 VLM 本身的视觉反馈；或仅限于特定任务，泛化能力不足。                                            | 使用单一 VLM 作为任务规划器和成功检测器，实现了闭环的任务执行，并通过自生成记忆进行学习。                                  |
| **用于动作规划的图像标注** | 结合以对象为中心的标注（如掩码）和抓取工具来支持语义对象抓取等任务。                               | 通常局限于平面桌面操作或单一的抓取任务。                                                                                         | 引入了按需的图像标注工具，支持在 3D 空间中进行多种技能的精确操作，而不仅仅是抓取。                                         |
| **自我反思和机器人记忆**   | 让基于 LLM 的机器人反思失败并从经验中学习。例如 REFLECT, ComeRobot。                               | 通常需要外部监督信号，因为 LLM 本身没有视觉反馈。虽然近期 VLM 使得机器人能够自我反思，但如何利用这些经验来提升未来性能仍需探索。 | EXPTEACH 不仅能实现自我反思，还能将反思总结并存入长期记忆，通过 RAG 机制指导未来的任务，并验证了其在未见场景中的泛化能力。 |

### 方法

EXPTEACH 框架的核心思想是让 VLM 通过与物理世界交互产生的经验来自我“接地”。它主要由 VLM 任务规划器 (T) 和成功检测器 (D) 构成，并通过一个包含短期记忆 (m) 和长期记忆 (M) 的记忆机制来增强。

1.  **VLM 任务规划 (VLM Task Planning)**
    *   使用同一个 VLM 模型同时作为任务规划器 $T$ 和成功检测器 $D$。
    *   规划器 $T$ 接收用户指令 $I$ 和 RGB 图像，生成动作计划。
    *   每次动作执行后，成功检测器 $D$ 根据视觉观察 $o$ 评估反馈信号 $r$，包括场景描述、动作成功或失败、失败原因分析以及下一步建议。
    *   该反馈通过短期记忆 (STM) 传递给规划器 $T$。

2.  **短期记忆 (Short-Term Memory, STM)**
    *   STM 在任务执行过程中扮演关键角色，用于动态地反思、重新规划和从失败中恢复。
    *   它以迭代方式运作，存储当前任务的动作日志，每个条目包含一个动作 $a_t$ 及其关联的反馈 $r_{t+1}$。
    *   公式表达为：$ m = \{(a_\tau, r_{\tau+1})\}_{\tau=0}^{t-1} = \{(a_\tau, D(a_\tau, o_{\tau+1}))\}_{\tau=0}^{t-1} $
    *   在失败的情况下，STM 使机器人能够识别更好的策略，例如使用工具或与非目标物体交互以完成任务。

3.  **长期记忆 (Long-Term Memory, LTM)**
    *   LTM 用于自主积累知识和经验。当一个任务成功完成后，其 STM 中的内容会被一个 VLM 经验总结器 $\mathcal{E}$ 概括，并以键值对 $(K, E)$ 的形式存入 LTM。
    *   其中，键 $K$ 是由用户指令 $I$ 和初始场景描述组成的场景描述，值 $E$ 是相关的总结经验。
    *   当面临新任务时，系统使用检索增强生成 (RAG) 流程：将当前任务的指令和场景描述作为查询，利用余弦相似度从 LTM 中检索最相关的过往经验，并将这些经验融入到任务规划的提示中，从而指导 VLM 从一开始就做出正确的决策。

4.  **通过图像标注增强技能集 (Enhanced Skillset with Image Annotations)**
    *   为了解决抓取、放置、推动等操作中精确定位困难的问题，引入了一个按需图像标注工具。
    *   当 VLM 判断需要精确操作时，系统会使用 Grounded SAM 对目标物体进行分割，并在图像上叠加一组候选位置掩码。
    *   VLM 随后从这些标注的选项中选择最合适的位置来执行动作，从而显著提高了操作的精度和成功率。

### 实验与结论

#### 实验设置

*   **硬件**: 使用一个腿式操作机器人 ANYmal，它是一个四足机器人，配备一个 6-DoF 的手臂和一个 Robotiq 2F-140 夹爪。
*   **VLM**: 实验采用 gpt-4o 作为核心的视觉语言模型。
*   **任务**: 设计了一系列具有挑战性的物体操纵任务，包括处理物体遮挡、使用工具以及与易碎物体的交互。

#### 实验结果

1.  **短期记忆与自我反思的评估**: 在 4 个挑战性任务中，与没有 STM 的基线模型 CaP-V 相比，EXPTEACH 的成功率有显著提升（例如，在“将苹果放到盘子里（有容器阻挡）”任务中，成功率从 50% 提升至 86%）。这证明了 STM 在失败后进行反思和调整策略的关键作用。

2.  **通过自生成记忆进行 VLM 接地**: 实验构建了一个包含 100 个条目的 LTM。在与没有 LTM 的基线 ComeRobot 的对比中，EXPTEACH 在多个任务上的单次成功率实现了大幅提升（例如，在“把苹果放到盘子里”任务中，成功率从 29% 提升到 100%）。这表明 LTM 可以有效地存储和检索经验，并成功泛化到新的、结构相似的场景中。

3.  **记忆检索消融研究**: 对比了三种记忆检索策略：随机检索、提供整个 LTM 和通过 RAG 检索 top-k。结果显示，RAG 策略取得了最好的性能 (89% 的任务规划成功率)，而随机检索效果最差 (27%)，提供全部 LTM (67%) 则可能因为信息过载而导致性能下降。

4.  **图像标注模块消融研究**: 实验证明，在处理复杂形状或需要特定抓取点的物体时，图像标注模块能显著提高抓取成功率。同时，在推动任务中，它也能有效减少与目标位置的距离误差。

#### 结论

该论文提出的 EXPTEACH 框架通过让 VLM 从自我生成的短期和长期记忆中学习，成功地将其“落地”到真实的机器人系统中。实验结果表明，该方法能够让机器人自主地进行反思和适应，从而显著提高任务成功率，并实现了包括创造性使用工具在内的智能物体交互。这项工作为集成 VLM 和机器人系统提供了一个通用的框架，是迈向通用机器人系统发展的重要一步。

### 不足

论文同样指出了当前工作的一些局限性，并展望了未来的研究方向：

*   **任务领域的局限性**: 目前的研究完全集中在操纵任务上。尽管核心方法具有普适性，但未来计划将其扩展到移动操纵任务。
*   **单一模态反馈**: 当前系统假设仅靠视觉反馈就足以进行理解和决策。在实际中，某些场景需要多模态反馈，如触觉或听觉信号，集成这些模态可以极大地提升系统能力。
*   **缺乏用户对齐**: 该工作尚未探索如何将机器人的记忆与用户的偏好对齐。未来计划将用户对齐的记忆融入框架，以实现更个性化和上下文感知的行为。
*   **任务的自主生成**: 受 Self-Instruct 的启发，未来的一个有趣方向是让 VLM 能够自主提出任务、生成指令并从结果中学习，从而进一步减少人工干预。

#### 与我的 idea 的区别

## Ref and Tag